{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks \n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df,label, batch_size=128):\n",
    "\n",
    "       \n",
    "        self.main_dataset = df.to_numpy()\n",
    "        self.main_label = label.reshape(-1)\n",
    "        self.no_of_fetures = len(df.columns)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.training_dataset = None \n",
    "        self.training_label = None\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.training_dataset) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X = self.training_dataset[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        y = self.training_label[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        positive_index = self.main_label == 1\n",
    "        negative_index = self.main_label == 0\n",
    "        \n",
    "        positive_data = self.main_dataset[positive_index]\n",
    "        negative_data = self.main_dataset[negative_index]\n",
    "        \n",
    "        #print('Negative: ' ,len(negative_index),negative_index.shape ,'Positive: ',len(positive_index))\n",
    "        \n",
    "        index = np.random.choice(negative_data.shape[0], size=positive_data.shape[0], replace=False)\n",
    "        \n",
    "        negative_data = negative_data[index]\n",
    "\n",
    "        self.training_dataset =  np.concatenate((positive_data, negative_data), axis=0)\n",
    "        self.training_label = np.array([1]*len(positive_data) + [0]*len(negative_data))\n",
    "        \n",
    "        self.training_dataset , self.training_label = shuffle(self.training_dataset, self.training_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    MODEL_SAVE_DIR = 'logs'\n",
    "cfg = CFG()\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\",\n",
    "                                    restore_best_weights=True, patience=10\n",
    "                                    )\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath=os.path.join('logs\\saved_model', \"{epoch:04d}-{val_accuracy:.3f}.h5\"),\n",
    "                                        save_weights_only=False,\n",
    "                                        monitor='val_accuracy',\n",
    "                                        model='max',\n",
    "                                        save_best_only=False,\n",
    "                                    )\n",
    "\n",
    "csv_logs = callbacks.CSVLogger(os.path.join(cfg.MODEL_SAVE_DIR, \"logs.csv\"))\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(factor=0.66, monitor=\"val_accuracy\", mode=\"max\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(no_of_columns,show_summary=False):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=no_of_columns)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(inp)\n",
    "    #x = tf.keras.layers.BatchNormalization() (x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.33)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.33)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer= tf.optimizers.Adam(learning_rate=.007) , metrics=['accuracy'])\n",
    "\n",
    "    if show_summary: model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('processed_df.xlsx')\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 46)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3008      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,161\n",
      "Trainable params: 36,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(len(df.columns)-1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = df.min()\n",
    "max_ = df.max()\n",
    "normalized_df=(df-min_)/(max_-min_)\n",
    "\n",
    "label = normalized_df['label']\n",
    "normalized_df = normalized_df.drop(['label'], axis = 1)\n",
    "\n",
    "X,XTEST,Y, YTEST = train_test_split(normalized_df,label,test_size = .2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = DataGenerator(X,Y.to_numpy(), batch_size=128)\n",
    "valid_data_gen = DataGenerator(XTEST,YTEST.to_numpy(), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data_gen,\n",
    "          epochs=300,\n",
    "          validation_data=valid_data_gen,\n",
    "          callbacks=[ checkpoint, csv_logs, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(r'logs/0046-0.810.h5')\n",
    "prediction = np.round(model.predict(XTEST)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3789  921]\n",
      " [ 207  748]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.80      0.87      4710\n",
      "         1.0       0.45      0.78      0.57       955\n",
      "\n",
      "    accuracy                           0.80      5665\n",
      "   macro avg       0.70      0.79      0.72      5665\n",
      "weighted avg       0.86      0.80      0.82      5665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(YTEST, prediction))\n",
    "print(classification_report(YTEST, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf2.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57baf32a60234b0d3f41053f5b8d37d9342cc4e1e7ef48b23997de928c59b639"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
